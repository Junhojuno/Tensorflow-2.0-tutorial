{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_CNN_2.0style",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Junhojuno/Tensorflow-2.0-tutorial/blob/master/01_CNN_2_0style.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OGYisw0puyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models, Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zhSjWMbqBU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fecc4f2c-eaa1-4249-aa02-e16b988204e2"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images[..., tf.newaxis] # train_images = train_images.reshape((60000, 28, 28, 1))와 같은 의미\n",
        "test_images = test_images[..., tf.newaxis] # test_images = test_images.reshape((10000, 28, 28, 1))와 같은 의미\n",
        "\n",
        "\n",
        "# 픽셀 값을 0~1 사이로 정규화합니다.\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "print(\"train image shape : {} \\n test images shape : {}\".format(train_images.shape, test_images.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train image shape : (60000, 28, 28, 1) \n",
            " test images shape : (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtYcyUZWp9L3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.data를 활용하여 data slicing\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDjjgRQMsxoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.keras로 subclassing\n",
        "\n",
        "class CNN(Model):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')\n",
        "        self.maxpool1 = layers.MaxPooling2D((2,2))\n",
        "        self.conv2 = layers.Conv2D(64, (3,3), activation='relu')\n",
        "        self.maxpool2 = layers.MaxPooling2D((2,2))\n",
        "        self.conv3 = layers.Conv2D(64, (3,3), activation='relu')\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.dense1 = layers.Dense(64, activation='relu')\n",
        "        self.dense2 = layers.Dense(10, activation='sigmoid')\n",
        "        \n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)\n",
        "\n",
        "model = CNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cHO5JsowlhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer, loss 설정\n",
        "# tf.keras.losses.SparseCategoricalCrossentropy() : [[1],[3],[0],.....]와 같이 one-hot encoding이 안 된 상태일때 사용\n",
        "# https://www.reddit.com/r/MLQuestions/comments/93ovkw/what_is_sparse_categorical_crossentropy/\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='Training loss')\n",
        "train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='Training accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='Test loss')\n",
        "test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='Test accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Pnwmknx5e5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.GradientTape() : Record operations for automatic differentiation.\n",
        "\n",
        "# apply_gradient : Apply gradients to variables.\n",
        "# This is the second part of `minimize()`. It returns an `Operation` that applies gradient\n",
        "\n",
        "@tf.function\n",
        "def training_step(images, labels):\n",
        "    with tf.GradientTape() as g:\n",
        "        prediction = model(images)\n",
        "        loss = loss_object(labels, prediction)\n",
        "    \n",
        "    gradient = g.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
        "    \n",
        "    train_loss(loss) # 배치 사이즈 loss 평균때리기?\n",
        "    train_acc(labels, prediction)\n",
        "    \n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    prediction = model(images)\n",
        "    loss = loss_object(labels, prediction)\n",
        "    \n",
        "    test_loss(loss)\n",
        "    test_acc(labels, prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70FOFS6q1FtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB_IcAb90TAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "64198393-f6c0-4e93-a56a-a5e9196d7cf0"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "start = time.time()  # 시작 시간 저장 \n",
        " \n",
        "for epoch in range(epochs):\n",
        "    for image, label in train_ds:\n",
        "        training_step(image, label)\n",
        "        \n",
        "    for image, label in test_ds:\n",
        "        test_step(image, label)\n",
        "        \n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print(template.format(epoch+1,                   \n",
        "                          train_loss.result(),\n",
        "                          train_acc.result()*100,\n",
        "                          test_loss.result(),\n",
        "                          test_acc.result()*100))\n",
        "    \n",
        "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.11205559968948364, Accuracy: 96.52749633789062, Test Loss: 0.05645560473203659, Test Accuracy: 98.1050033569336\n",
            "Epoch 2, Loss: 0.08766008913516998, Accuracy: 97.28055572509766, Test Loss: 0.04987150430679321, Test Accuracy: 98.36000061035156\n",
            "Epoch 3, Loss: 0.0729563906788826, Accuracy: 97.73500061035156, Test Loss: 0.04925883561372757, Test Accuracy: 98.41999816894531\n",
            "Epoch 4, Loss: 0.06289923936128616, Accuracy: 98.0469970703125, Test Loss: 0.0470350943505764, Test Accuracy: 98.52999877929688\n",
            "Epoch 5, Loss: 0.05531470850110054, Accuracy: 98.27777862548828, Test Loss: 0.04474099352955818, Test Accuracy: 98.61500549316406\n",
            "time : 68.07280421257019\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}